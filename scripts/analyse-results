#!/usr/bin/env python

"""Analyse the results of a demo."""

from pathlib import Path
import re
import argparse
import itertools
import operator as op
import pickle
import logging
import numpy as np
import pandas as pd
import altair as alt
from dynlearn import demo, optimiser as opt

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

RESULTS_RE = re.compile('(.+)-results')

plots_dir = Path('plots')
results_dir = Path('results')

# import sys
# sys.argv = [
#     'analyse-results',
#     # 'results/nanog50-active-10-20-1-123456-1000-results.pkl',
#     'results/nanog50-active-10-20-6-123456-1000-results.pkl',
# ]

# Parse arguments
parser = argparse.ArgumentParser()
parser.add_argument('result_path', type=Path, action='append')
args = parser.parse_args()

# seeds = range(139, 148)
# def result_paths_for_seeds(seeds):
#     for seed in seeds:
#         yield results_dir / f'nanog50-random-20-40-{seed}-1000-results.pkl'
#         yield results_dir / f'nanog50-Bayesian-20-30-{seed}-1000-results.pkl'
#         yield results_dir / f'nanog50-Powell-20-20-{seed}-1000-results.pkl'
#         yield results_dir / f'nanog50-active-20-10-{seed}-1000-results.pkl'
#
# result_paths = [results_dir / 'nanog50-random-20-40-37-1000-results.pkl',
#                 results_dir / 'nanog50-Bayesian-20-30-37-1000-results.pkl',
#                 results_dir / 'nanog50-Powell-20-20-37-1000-results.pkl',
#                 # results_dir / 'nanog50-active-20-10-37-1000-results.pkl',
#                 results_dir / 'nanog50-random-20-40-38-1000-results.pkl',
#                 results_dir / 'nanog50-Bayesian-20-30-38-1000-results.pkl',
#                 results_dir / 'nanog50-Powell-20-20-38-1000-results.pkl',
#                 # results_dir / 'nanog50-active-20-10-38-1000-results.pkl',
#                 ]
# result_path = results_dir / 'nanog50-active-20-10-40-1000-results.pkl'

_losses = list()
for result_path in args.result_path:
    results = pickle.load(result_path.open('rb'))
    tag = RESULTS_RE.match(result_path.with_suffix('').name).group(1)
    args = demo.args_from_tag(tag)
    best_u = results['best_u']
    sim, loss_fn, gp, knots, knot_values, plot_args = demo.setup(args)
    target = opt.OptimisationTarget(sim, loss_fn, knots)
    epoch_us = np.array([tracks[:1] for tracks in results['history']])
    # losses_from_tracks = np.array([target.loss_from_tracks(tracks) for tracks in results['history']])
    losses_from_us = np.array([target.loss_from_tracks(sim.tracks_for_u(u.T)) for u in epoch_us])
    # assert np.isclose(losses_from_tracks, losses_from_us).all()
    losses_best = list(opt.min_so_far(losses_from_us))
    df = pd.DataFrame((pd.Series(losses_from_us, name='epoch_loss'),
                       pd.Series(losses_best, name='best_loss'))).T
    df['optimiser'] = args.optimiser
    df['seed'] = args.seed
    df.index.name = 'experiments'
    df = df.reset_index()
    _losses.append(df.melt(id_vars=['optimiser', 'seed', 'experiments'], value_name='loss'))

losses = pd.concat(_losses, axis=0)

if False:  # WIP
    results.keys()
    results['history'].shape
    epoch_results = results['epoch_results']
    len(epoch_results)
    epoch_results[0].keys()
    epoch_results[0]['sampled_tracks'].shape
    sampled_tracks = np.asarray(list(map(op.itemgetter('sampled_tracks'), epoch_results)))
    sampled_tracks.shape
    sampled_tracks[:, :, :, 0] /= 10
    control_vars = ['U (scaled)']

    species = list(itertools.chain(control_vars, sim.output_vars))
    sampled_tracks_df = opt.array_as_series(sampled_tracks, (('epoch', None),
                                                             ('sample', None),
                                                             ('time_step', None),
                                                             ('species', species))).reset_index()
    sampled_tracks_df

    chart = (
        alt.Chart(sampled_tracks_df)
        .mark_line()
        .encode(x='time_step:O',
                y='value:Q',
                color='species:N',
                # strokeDash='control:N',
                detail='sample',
                facet=alt.Facet('epoch:O', columns=3)))
    chart.save('plots/sampled.svg')

# Melt losses to make chart
losses_chart = (
    losses
    .loc['best_loss' == losses['variable']]
    .query('experiments <= 18'))
losses_chart

# Make chart
loss_chart = (
    alt.Chart(losses_chart)
    .mark_line(clip=True)
    .encode(x=alt.X('experiments:O'),
            # y=alt.Y('loss:Q', scale=alt.Scale(domain=(0, 200))),
            y=alt.Y('loss:Q'),
            color='optimiser:N',
            detail='seed')
    .properties(width=300, height=200))
# loss_chart.save('plots/optimiser-losses.png', scale_factor=10.)
losses_path = plots_dir / 'optimiser-losses.svg'
logger.info('Saving optimiser losses: %s', losses_path)
loss_chart.save('plots/optimiser-losses.svg')
